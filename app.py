import streamlit as st
import google.generativeai as genai
from supabase import create_client, Client
from dotenv import load_dotenv
import os

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_title="Focus Shield AI Assistant",
    page_icon="üõ°Ô∏è",
    layout="centered"
)

# 2. ‡πÇ‡∏´‡∏•‡∏î Key ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö
@st.cache_resource
def init_connections():
    load_dotenv()
    
    GEMINI_KEY = os.getenv("GEMINI_API_KEY")
    SUPA_URL = os.getenv("SUPABASE_URL")
    SUPA_KEY = os.getenv("SUPABASE_KEY")
    
    if not GEMINI_KEY:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .env ‡∏´‡∏£‡∏∑‡∏≠ Secrets ‡πÉ‡∏ô Cloud")
        return None, None, None

    # Connect Gemini
    genai.configure(api_key=GEMINI_KEY)
    
    # Auto-detect ‡πÇ‡∏°‡πÄ‡∏î‡∏• Flash ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô main.py)
    # ‡πÅ‡∏ï‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 1.5-flash ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á gemini-3-flash ‡∏ó‡∏µ‡πà‡∏°‡∏µ quota ‡∏ô‡πâ‡∏≠‡∏¢
    model_name = None
    try:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ 1.5-flash ‡∏Å‡πà‡∏≠‡∏ô (quota ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤)
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if 'flash' in m.name.lower() and '1.5' in m.name.lower():
                    model_name = m.name.replace("models/", "")
                    break
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ 1.5-flash ‡∏•‡∏≠‡∏á‡∏´‡∏≤ flash ‡∏ï‡∏±‡∏ß‡∏≠‡∏∑‡πà‡∏ô (‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤ 3-flash)
        if not model_name:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    if 'flash' in m.name.lower() and '3' not in m.name.lower():
                        model_name = m.name.replace("models/", "")
                        break
        
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ gemini-pro ‡∏´‡∏£‡∏∑‡∏≠ gemini-1.5-pro
        if not model_name:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    if 'pro' in m.name.lower() and '1.5' in m.name.lower():
                        model_name = m.name.replace("models/", "")
                        break
            
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤ list_models() ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ default
        model_name = 'gemini-1.5-flash'
        st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ default: {model_name}")
    
    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢ ‡πÉ‡∏ä‡πâ default
    if not model_name:
        model_name = 'gemini-1.5-flash'
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ñ‡πâ‡∏≤ error ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ô get_focus_response)
    try:
        model = genai.GenerativeModel(model_name)
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
        st.warning(f"‚ö†Ô∏è ‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name} ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô...")
        model = None
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    try:
                        model = genai.GenerativeModel(m.name.replace("models/", ""))
                        model_name = m.name.replace("models/", "")
                        break
                    except:
                        continue
        except:
            pass
        
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ default ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        if model is None:
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                model_name = 'gemini-1.5-flash'
            except:
                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ gemini-pro
                model = genai.GenerativeModel('gemini-pro')
                model_name = 'gemini-pro'
    
    # Connect Supabase
    supabase = create_client(SUPA_URL, SUPA_KEY)
    
    return model, supabase, model_name

model, supabase, active_model_name = init_connections()

# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏°‡∏≠‡∏á AI
def get_focus_response(user_input, history_text):
    try:
        # Vector Search
        query_vec = genai.embed_content(
            model="models/text-embedding-004",
            content=user_input
        )['embedding']

        results = supabase.rpc(
            "match_products",
            {
                "query_embedding": query_vec,
                "match_threshold": 0.35,
                "match_count": 5
            }
        ).execute()

        # Context
        context = ""
        if results.data:
            for item in results.data:
                meta = item['metadata']
                price = meta.get('price', '-')
                link = meta.get('link', '#')
                context += f"- {item['content']} (‡∏£‡∏≤‡∏Ñ‡∏≤: {price} | Link: {link})\n"
        else:
            context = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"

        # Prompt
        final_prompt = f"""
        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™" ‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏Ç‡∏≤‡∏¢‡∏ü‡∏¥‡∏•‡πå‡∏° Focus Shield
        [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤]
        {context}
        [‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢]
        {history_text}
        [‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤]
        {user_input}
        
        --- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ---
        1. ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢/‡∏ñ‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ
        2. ‡πÄ‡∏™‡∏ô‡∏≠‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡πÉ‡∏™/‡∏î‡πâ‡∏≤‡∏ô/‡∏Å‡∏±‡∏ô‡∏°‡∏≠‡∏á) ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡∏£‡∏∏‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß
        3. ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (‡∏£‡∏≤‡∏Ñ‡∏≤+‡∏•‡∏¥‡∏á‡∏Å‡πå) ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏Ñ‡∏£‡∏ö
        4. ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        5. ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
        """
        
        response = model.generate_content(final_prompt)
        return response.text
    except Exception as e:
        error_msg = str(e)
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ quota exceeded (429)
        if "429" in error_msg or "quota" in error_msg.lower() or "exceeded" in error_msg.lower():
            return """üòÖ ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å ‡∏ó‡∏≥‡πÉ‡∏´‡πâ quota ‡∏´‡∏°‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Ñ‡πà‡∏∞ 
            
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ)
- ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ (quota ‡∏à‡∏∞ reset ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô)

‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏õ‡πá‡∏ô paid plan ‡∏Ç‡∏≠‡∏á Google Gemini API ‡∏Ñ‡πà‡∏∞

‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè"""
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ model not found (404)
        if "404" in error_msg or "not found" in error_msg.lower() or "not supported" in error_msg.lower():
            return """‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô API version ‡∏ô‡∏µ‡πâ

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÉ‡∏´‡∏°‡πà

‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡∏°‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Ñ‡πà‡∏∞"""
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ error ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
        return f"""‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {error_msg}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡∏°‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Ñ‡πà‡∏∞"""

# 4. UI
st.title("üõ°Ô∏è ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™ (AI Assistant)")
st.caption(f"Model: {active_model_name} | Powered by Supabase")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≠‡∏á‡∏´‡∏≤‡∏ü‡∏¥‡∏•‡πå‡∏°‡∏£‡∏∏‡πà‡∏ô‡πÑ‡∏´‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡πà‡∏∞? üòä"}
    ]

for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant", avatar="üõ°Ô∏è").write(msg["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    history_str = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-4:]])

    with st.spinner("‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå..."):
        response_text = get_focus_response(prompt, history_str)

    st.chat_message("assistant", avatar="üõ°Ô∏è").write(response_text)
    st.session_state.messages.append({"role": "assistant", "content": response_text})