import streamlit as st
import google.generativeai as genai
from supabase import create_client, Client
from dotenv import load_dotenv
import os

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_title="Focus Shield AI Assistant",
    page_icon="üõ°Ô∏è",
    layout="centered"
)

# 2. ‡πÇ‡∏´‡∏•‡∏î Key ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö
@st.cache_resource
def init_connections():
    load_dotenv()
    
    GEMINI_KEY = os.getenv("GEMINI_API_KEY")
    SUPA_URL = os.getenv("SUPABASE_URL")
    SUPA_KEY = os.getenv("SUPABASE_KEY")
    
    if not GEMINI_KEY:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .env ‡∏´‡∏£‡∏∑‡∏≠ Secrets ‡πÉ‡∏ô Cloud")
        return None, None, None

    # Connect Gemini
    genai.configure(api_key=GEMINI_KEY)
    
    # Auto-detect ‡πÇ‡∏°‡πÄ‡∏î‡∏• Flash ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    model_name = 'gemini-1.5-flash'  # Default
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if 'flash' in m.name.lower():
                    model_name = m.name.replace("models/", "")
                    if '1.5' in m.name: 
                        break
    except Exception as e:
        st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• Flash ‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ default: {model_name}")
    
    model = genai.GenerativeModel(model_name)
    
    # Connect Supabase
    supabase = create_client(SUPA_URL, SUPA_KEY)
    
    return model, supabase, model_name

model, supabase, active_model_name = init_connections()

# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏°‡∏≠‡∏á AI
def get_focus_response(user_input, history_text):
    try:
        # Vector Search
        query_vec = genai.embed_content(
            model="models/text-embedding-004",
            content=user_input
        )['embedding']

        results = supabase.rpc(
            "match_products",
            {
                "query_embedding": query_vec,
                "match_threshold": 0.35,
                "match_count": 5
            }
        ).execute()

        # Context
        context = ""
        if results.data:
            for item in results.data:
                meta = item['metadata']
                price = meta.get('price', '-')
                link = meta.get('link', '#')
                context += f"- {item['content']} (‡∏£‡∏≤‡∏Ñ‡∏≤: {price} | Link: {link})\n"
        else:
            context = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"

        # Prompt
        final_prompt = f"""
        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™" ‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏Ç‡∏≤‡∏¢‡∏ü‡∏¥‡∏•‡πå‡∏° Focus Shield
        [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤]
        {context}
        [‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢]
        {history_text}
        [‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤]
        {user_input}
        
        --- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ---
        1. ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢/‡∏ñ‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ
        2. ‡πÄ‡∏™‡∏ô‡∏≠‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡πÉ‡∏™/‡∏î‡πâ‡∏≤‡∏ô/‡∏Å‡∏±‡∏ô‡∏°‡∏≠‡∏á) ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡∏£‡∏∏‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß
        3. ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (‡∏£‡∏≤‡∏Ñ‡∏≤+‡∏•‡∏¥‡∏á‡∏Å‡πå) ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏Ñ‡∏£‡∏ö
        4. ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        5. ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
        """
        
        response = model.generate_content(final_prompt)
        return response.text
    except Exception as e:
        return f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}"

# 4. UI
st.title("üõ°Ô∏è ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™ (AI Assistant)")
st.caption(f"Model: {active_model_name} | Powered by Supabase")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≠‡∏á‡∏´‡∏≤‡∏ü‡∏¥‡∏•‡πå‡∏°‡∏£‡∏∏‡πà‡∏ô‡πÑ‡∏´‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö? üòä"}
    ]

for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant", avatar="üõ°Ô∏è").write(msg["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    history_str = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-4:]])

    with st.spinner("‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå..."):
        response_text = get_focus_response(prompt, history_str)

    st.chat_message("assistant", avatar="üõ°Ô∏è").write(response_text)
    st.session_state.messages.append({"role": "assistant", "content": response_text})