import os
import time
import google.generativeai as genai
from supabase import create_client, Client
from dotenv import load_dotenv

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠ Key ‡πÑ‡∏´‡∏°
if not GEMINI_API_KEY or not SUPABASE_URL:
    print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ‡πÑ‡∏ü‡∏•‡πå .env")
    exit()

# 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö
try:
    genai.configure(api_key=GEMINI_API_KEY)
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
except Exception as e:
    print(f"‚ùå ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô: {e}")

# 3. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• Flash ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• Flash...")
final_model_name = ""

try:
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            if 'flash' in m.name.lower():
                final_model_name = m.name
                if '1.5' in m.name: break 

    if final_model_name:
        print(f"üéØ ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•: {final_model_name}")
        clean_name = final_model_name.replace("models/", "")
        model = genai.GenerativeModel(clean_name)
    else:
        print("‚ö†Ô∏è ‡∏´‡∏≤ Flash ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô")
        model = genai.GenerativeModel('gemini-1.5-flash') # Default

except Exception as e:
    print(f"‚ùå Error ‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")

# 4. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏ä‡∏ó
def ask_focus(user_question, chat_history_text):
    print("ü§ñ ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô Vector
        query_vec = genai.embed_content(
            model="models/text-embedding-004",
            content=user_question
        )['embedding']

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô Supabase
        results = supabase.rpc(
            "match_products",
            {
                "query_embedding": query_vec,
                "match_threshold": 0.35,
                "match_count": 5
            }
        ).execute()
        
        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        context = ""
        found_items = []
        if results.data:
            for item in results.data:
                meta = item['metadata']
                model_name = meta.get('model', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∏‡πà‡∏ô')
                link = meta.get('link', '#')
                price = meta.get('price', '-')
                context += f"- {item['content']} (‡∏£‡∏≤‡∏Ñ‡∏≤: {price} | Link: {link})\n"
                found_items.append(model_name)
        else:
            context = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"

        print(f"   (‡πÄ‡∏à‡∏≠: {', '.join(found_items)})") 

        # Prompt
        final_prompt = f"""
        ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™" ‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏Ç‡∏≤‡∏¢‡∏ü‡∏¥‡∏•‡πå‡∏° Focus Shield
        
        [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ñ‡∏•‡∏±‡∏á]
        {context}
        
        [‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢]
        {chat_history_text}
        
        [‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤]
        {user_question}
        
        --- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö ---
        1. "‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô" ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡πÅ‡∏Ñ‡πà‡∏ß‡πà‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏ü‡∏¥‡∏•‡πå‡∏° ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏£‡∏∏‡πà‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠
        2. "‡πÄ‡∏™‡∏ô‡∏≠‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å" ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡∏£‡∏∏‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏ü‡∏¥‡∏•‡πå‡∏°‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö (‡πÉ‡∏™/‡∏î‡πâ‡∏≤‡∏ô/‡∏Å‡∏±‡∏ô‡∏°‡∏≠‡∏á) ‡πÉ‡∏´‡πâ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö
        3. "‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢" ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå
        4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ ‡∏ß‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏î
        5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏û‡∏π‡∏î ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
        """

        response = model.generate_content(final_prompt)
        return response.text

    except Exception as e:
        return f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}"

# --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ---
if __name__ == "__main__":
    print("\nüéâ ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™ (PC Version) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô! (‡∏û‡∏¥‡∏°‡∏û‡πå exit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö)")
    history_log = []

    while True:
        try:
            q = input("\nüí¨ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: ")
            if q.lower() == 'exit': break
            if q.strip() == "": continue
            
            hist_text = "\n".join([f"{h['role']}: {h['msg']}" for h in history_log[-3:]])
            ans = ask_focus(q, hist_text)
            
            print(f"\n‚ö° ‡∏ô‡πâ‡∏≠‡∏á‡πÇ‡∏ü‡∏Å‡∏±‡∏™:\n{ans}")
            print("-" * 50)
            
            history_log.append({"role": "User", "msg": q})
            history_log.append({"role": "Focus", "msg": ans})
        except KeyboardInterrupt:
            print("\n‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
            break